#!/bin/bash

# ========================================================
# é’ˆå¯¹ pfaf_project ç›®å½•ç»“æž„ä¼˜åŒ–çš„å¯åŠ¨è„šæœ¬
# ========================================================

echo "ðŸš€ å¯åŠ¨ Hugging Face Spaces åº”ç”¨..."

# è®¾ç½®ä¿¡å·å¤„ç†
trap 'echo "ðŸ›‘ åœæ­¢ä¸­..."; kill $HTTP_PID 2>/dev/null; exit 0' SIGTERM SIGINT

# 1. å¯åŠ¨ HTTP æœåŠ¡å™¨ (ç›‘å¬ 7860 ç«¯å£)
python3 -m http.server 7860 &
HTTP_PID=$!

sleep 3
echo "ðŸ“¡ HTTP æœåŠ¡å™¨å·²å¯åŠ¨ (PID: $HTTP_PID)"

# 2. å¾ªçŽ¯æ‰§è¡Œçˆ¬è™«
COUNTER=0
while true; do
    COUNTER=$((COUNTER + 1))
    echo ""
    echo "========================================"
    echo "ðŸ”„ ç¬¬ $COUNTER è½®çˆ¬è™«æ‰§è¡Œå¼€å§‹..."
    echo "â° å½“å‰æ—¶é—´: $(date)"
    
    # ã€æ ¸å¿ƒä¿®å¤ç‚¹ã€‘è¿›å…¥åŒ…å« scrapy.cfg çš„å­ç›®å½•
    cd /app/pfaf_project
    
    # æ‰“å°å½“å‰ç›®å½•ç¡®è®¤ä¸€ä¸‹ (è°ƒè¯•ç”¨)
    echo "ðŸ“‚ å½“å‰è¿è¡Œç›®å½•: $(pwd)"
    
    # æ‰§è¡Œçˆ¬è™«
    # æ³¨æ„ï¼šè¯·ç¡®ä¿ pfaf_repair æ˜¯ä½ åœ¨ spiders ç›®å½•ä¸‹å®šä¹‰çš„çˆ¬è™«å
    if scrapy crawl pfaf_repair --loglevel=INFO; then
        echo "âœ… çˆ¬è™«æ‰§è¡ŒæˆåŠŸå®Œæˆ"
    else
        echo "âš ï¸ çˆ¬è™«æ‰§è¡Œé‡åˆ°é”™è¯¯ï¼Œè¯·æ£€æŸ¥é¡¹ç›®åæˆ–çˆ¬è™«å"
    fi
    
    echo "â° å®Œæˆæ—¶é—´: $(date)"
    echo "â³ ç­‰å¾… 300 ç§’åŽå†æ¬¡æ‰§è¡Œ..."
    sleep 300
    
    # æ¯ 10 è½®æ¸…ç†ä¸€æ¬¡ç¼“å­˜
    if [ $((COUNTER % 10)) -eq 0 ]; then
        sync
    fi
done

# åœæ­¢æœåŠ¡å™¨
kill $HTTP_PID 2>/dev/null || true